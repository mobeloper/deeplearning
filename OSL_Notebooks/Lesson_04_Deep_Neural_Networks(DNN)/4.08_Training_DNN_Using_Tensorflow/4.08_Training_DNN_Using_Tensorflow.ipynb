{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Deep Neural Networks on Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import libraries\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import IPython\n",
    "from six.moves import urllib\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About the dataset\n",
    "- For the Boston housing dataset, we get 506 rows of data, with 13 features in each.\n",
    "- Our task is to build a regression model that takes these 13 features as input and output a single value prediction of the \n",
    " \"median value of owner-occupied homes (in $1000).\"\n",
    "|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model\n",
    "Building the neural network requires \n",
    "- configuring the layers of the model, \n",
    "- then compiling the model. \n",
    "- First we stack a few layers together using keras.Sequential. Next we configure the loss function, optimizer, and metrics to monitor.\n",
    "These are added during the model's compile step:\n",
    "\n",
    "Terminologies\n",
    "- Loss function - measures how accurate the model is during training, we want to minimize this with the optimizer.\n",
    "- Optimizer - how the model is updated based on the data it sees and its loss function.\n",
    "- Metrics - used to monitor the training and testing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "\n",
    "(train_features, train_labels), (test_features, test_labels) = keras.datasets.boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise the data\n",
    "\n",
    "train_mean = np.mean(train_features, axis=0)\n",
    "train_std = np.std(train_features, axis=0)\n",
    "train_features = (train_features - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.27224633, -0.48361547, -0.43576161, ...,  1.14850044,\n",
       "         0.44807713,  0.8252202 ],\n",
       "       [-0.40342651,  2.99178419, -1.33391162, ..., -1.71818909,\n",
       "         0.43190599, -1.32920239],\n",
       "       [ 0.1249402 , -0.48361547,  1.0283258 , ...,  0.78447637,\n",
       "         0.22061726, -1.30850006],\n",
       "       ...,\n",
       "       [-0.40202987,  0.99079651, -0.7415148 , ..., -0.71712291,\n",
       "         0.07943894, -0.67776904],\n",
       "       [-0.17292018, -0.48361547,  1.24588095, ..., -1.71818909,\n",
       "        -0.98764362,  0.42083466],\n",
       "       [-0.40422614,  2.04394792, -1.20161456, ..., -1.30866202,\n",
       "         0.23317118, -1.15392266]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "\n",
    "def build_model():\n",
    "    model = keras.Sequential([\n",
    "        Dense(20, activation=tf.nn.relu, input_shape=[len(train_features[0])]),\n",
    "        Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=tf.optimizers.Adam(), \n",
    "                  loss='mae',\n",
    "                  metrics='mean_absolute_error')\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Train the model\n",
    "Training the neural network model requires the following steps:\n",
    "\n",
    "- Feed the training data to the model—in this example, the train_features and train_labels arrays.\n",
    "- The model learns to associate features and labels.\n",
    "- We ask the model to make predictions about a test set—in this example, the test_features array. \n",
    "We verify that the predictions match the labels from the test_labels array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "Final  Mean absolute  Error on validation set: 2.553\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "class PrintDot(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if epoch % 100 == 0: print('')\n",
    "        print('.', end='')\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=50)\n",
    "history = model.fit(train_features, train_labels, epochs=200, verbose=0, validation_split = 0.1,\n",
    "                    callbacks=[early_stop, PrintDot()])\n",
    "\n",
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "\n",
    "# show RMSE measure to compare to Kaggle leaderboard on https://www.kaggle.com/c/boston-housing/leaderboard\n",
    "#rmse_final = np.sqrt(float(hist['val_mean_absolute_error'].tail(1)))\n",
    "mae_final = float(hist['val_mean_absolute_error'].tail(1))\n",
    "\n",
    "print()\n",
    "print('Final  Mean absolute  Error on validation set: {}'.format(round(mae_final, 3)))\n",
    "                  \n",
    "                  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step - loss: 2.8192 - mean_absolute_error: 2.8192\n",
      " Mean absolute  Error on test set: 2.819\n"
     ]
    }
   ],
   "source": [
    "# Mean absolute error on the test set\n",
    "\n",
    "test_features_norm = (test_features - train_mean) / train_std\n",
    "test_features_norm = (test_features - train_mean) / train_std\n",
    "mae,  _ = model.evaluate(test_features_norm, test_labels)\n",
    "#rmae = np.sqrt(mae)\n",
    "print(' Mean absolute  Error on test set: {}'.format(round(mae, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
