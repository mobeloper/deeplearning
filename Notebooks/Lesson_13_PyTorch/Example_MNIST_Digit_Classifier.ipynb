{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in /opt/anaconda3/lib/python3.11/site-packages (0.2.2)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.11/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: six in /Users/oysterable/.local/lib/python3.11/site-packages (from torchvision) (1.16.0)\n",
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.11/site-packages (from torchvision) (2.3.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.11/site-packages (from torch->torchvision) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/oysterable/.local/lib/python3.11/site-packages (from torch->torchvision) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.11/site-packages (from torch->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.11/site-packages (from torch->torchvision) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.11/site-packages (from torch->torchvision) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.11/site-packages (from torch->torchvision) (2023.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.11/site-packages (from jinja2->torch->torchvision) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/anaconda3/lib/python3.11/site-packages (from sympy->torch->torchvision) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip install torch\n",
    "!pip install torchvision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'PILLOW_VERSION' from 'PIL' (/opt/anaconda3/lib/python3.11/site-packages/PIL/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms\n\u001b[1;32m      5\u001b[0m transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([transforms\u001b[38;5;241m.\u001b[39mToTensor(), transforms\u001b[38;5;241m.\u001b[39mNormalize((\u001b[38;5;241m0.5\u001b[39m,), (\u001b[38;5;241m0.5\u001b[39m,))])\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torchvision/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datasets\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torchvision/datasets/__init__.py:9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msvhn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SVHN\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mphototour\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PhotoTour\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfakedata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FakeData\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msemeion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SEMEION\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01momniglot\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Omniglot\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torchvision/datasets/fakedata.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdata\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mFakeData\u001b[39;00m(data\u001b[38;5;241m.\u001b[39mDataset):\n\u001b[1;32m      7\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"A fake dataset that returns randomly generated images and returns them as PIL images\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m \n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torchvision/transforms/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torchvision/transforms/transforms.py:17\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m functional \u001b[38;5;28;01mas\u001b[39;00m F\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mversion_info \u001b[38;5;241m<\u001b[39m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m     20\u001b[0m     Sequence \u001b[38;5;241m=\u001b[39m collections\u001b[38;5;241m.\u001b[39mSequence\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torchvision/transforms/functional.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image, ImageOps, ImageEnhance, PILLOW_VERSION\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01maccimage\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'PILLOW_VERSION' from 'PIL' (/opt/anaconda3/lib/python3.11/site-packages/PIL/__init__.py)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "jROz8T2NJUDh",
    "outputId": "a361b576-9197-4017-86a5-72d7a93faee4"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "plt.imshow(images[6].numpy().squeeze(), cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "print(labels[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XWh_rtgkJdXw"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.softmax(self.fc3(x), dim=1)\n",
    "        return x\n",
    "\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aerqDox8KcFF"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M-MHTEEwKfY5",
    "outputId": "33f4c38f-59f0-427a-b69f-56abeafe4e4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.6295\n",
      "Epoch [2/10], Loss: 1.5407\n",
      "Epoch [3/10], Loss: 1.5247\n",
      "Epoch [4/10], Loss: 1.5159\n",
      "Epoch [5/10], Loss: 1.5115\n",
      "Epoch [6/10], Loss: 1.5077\n",
      "Epoch [7/10], Loss: 1.5045\n",
      "Epoch [8/10], Loss: 1.5023\n",
      "Epoch [9/10], Loss: 1.5004\n",
      "Epoch [10/10], Loss: 1.4996\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (images, labels) in enumerate(train_loader, 1): # Added enumeration to get batch number\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print average loss for the epoch\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/i:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1zEPRY82KiIP",
    "outputId": "b700d24b-b37c-4bb8-9e9d-bf7bb59e31b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 95.58%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Test Accuracy: {100 * correct / total}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "NrHKRJ0SK3Nr",
    "outputId": "71b54860-4ba5-4f1c-89bd-67775e30d588"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "outputs = model(images[1:2])\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "plt.imshow(images[1].numpy().squeeze(), cmap='gray')\n",
    "plt.title(f\"Predicted Label: {predicted.item()}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "64nI7QJtLHKI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 [3.10]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
