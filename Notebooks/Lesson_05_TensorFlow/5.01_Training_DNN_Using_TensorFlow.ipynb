{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0YnaxeLGCY4"
      },
      "source": [
        "# __Assisted Practice: Building Deep Neural Networks on TensorFlow__\n",
        "Building Deep Neural Networks on TensorFlow refers to the process of designing and constructing neural network models using the TensorFlow framework. This involves defining the architecture of the neural network, selecting appropriate layers and activation functions, specifying the optimization algorithm, and training the model using data.\n",
        "Let's understand how to build a neural network on TensorFlow."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Steps to Be Followed:\n",
        "1. Importing the required libraries\n",
        "2. Loading and inspecting the data\n",
        "3. Building the model\n",
        "4. Training the model"
      ],
      "metadata": {
        "id": "saSuWUrGGPIa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Importing Required Libraries\n",
        "\n",
        "- Import Pandas and NumPy packages\n",
        "- Import the TensorFlow package, which is used for text-based applications, image recognition, voice search, and many more\n",
        "- Import the Python package cv2, which is used for computer vision and image processing\n",
        "- Import the Python package matplotlib, which sets the padding between and around the subplots as well as the figure size\n",
        "- Import necessary libraries and modules for building a deep learning model using TensorFlow. It includes modules for convolutional and pooling layers, dropout, flattening, and dense layers\n",
        "- Imports other libraries for data manipulation, visualization, and image processing"
      ],
      "metadata": {
        "id": "zkfqjK31CXXV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qz6slja9GCY8"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import IPython\n",
        "from six.moves import urllib\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYhwB5u8GCY-"
      },
      "source": [
        "### Step 2: Loading and Inspecting the Data\n",
        "\n",
        "\n",
        "- It is loading the Boston Housing dataset using the **keras.datasets.boston_housing.load_data()** function.\n",
        "- It splits the dataset into two sets: the training set **train_features** and **train_labels** and the testing set **test_features** and **test_labels**.\n",
        "- The training set contains input features (e.g., crime rate and number of rooms) and corresponding target labels (e.g., the median value of owner-occupied homes).\n",
        "- The testing set is used to evaluate the trained model's performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaFEYTKKGCZA",
        "outputId": "312d9026-06e9-4ee3-dbf4-3e6f4757c2f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
            "57026/57026 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "\n",
        "(train_features, train_labels), (test_features, test_labels) = keras.datasets.boston_housing.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The mean **train_mean** and standard deviation **train_std** are calculated along the columns **axis=0** of the **train_features** array.\n",
        "- Then, the **train_features** array is standardized by subtracting the mean and dividing by the standard deviation.\n",
        "- This standardization process ensures that the features have a zero mean and unit variance, which can help improve the training performance and convergence of the model."
      ],
      "metadata": {
        "id": "N7cf4yntLbEK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "duafEb2UGCZA"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "train_mean = np.mean(train_features, axis=0)\n",
        "train_std = np.std(train_features, axis=0)\n",
        "train_features = (train_features - train_mean) / train_std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xo9x5HkuGCZB",
        "outputId": "ae3ba512-a869-4982-b0a1-507ed231fcd5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.27224633, -0.48361547, -0.43576161, ...,  1.14850044,\n",
              "         0.44807713,  0.8252202 ],\n",
              "       [-0.40342651,  2.99178419, -1.33391162, ..., -1.71818909,\n",
              "         0.43190599, -1.32920239],\n",
              "       [ 0.1249402 , -0.48361547,  1.0283258 , ...,  0.78447637,\n",
              "         0.22061726, -1.30850006],\n",
              "       ...,\n",
              "       [-0.40202987,  0.99079651, -0.7415148 , ..., -0.71712291,\n",
              "         0.07943894, -0.67776904],\n",
              "       [-0.17292018, -0.48361547,  1.24588095, ..., -1.71818909,\n",
              "        -0.98764362,  0.42083466],\n",
              "       [-0.40422614,  2.04394792, -1.20161456, ..., -1.30866202,\n",
              "         0.23317118, -1.15392266]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "train_features"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " __Observation__\n",
        "\n",
        "\n",
        "- Here, we can see a few Boston housing datasets.\n",
        "- The given array represents a multi-dimensional array containing numerical values.\n",
        "- Each row in the array corresponds to a set of features or data points, while each column represents a specific feature or variable."
      ],
      "metadata": {
        "id": "-_ZxZUEeF8iN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Building the Model\n",
        "Building the neural network requires:\n",
        "- Configuring the layers of the model and compiling the model.\n",
        "- Stacking a few layers together using **keras.Sequential**.\n",
        "- Configuring the loss function, optimizer, and metrics to monitor.\n",
        "These are added during the model's compile step.\n",
        "\n",
        "\n",
        "\n",
        "Terminologies:\n",
        "- The **Loss** function measures how accurate the model is during training; we want to minimize this with the optimizer.\n",
        "- One must **Optimize** how the model is updated based on the data it sees and its loss function.\n",
        "- **Metrics** are used to monitor the training and testing steps."
      ],
      "metadata": {
        "id": "v5fZchhYFbBZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kg01bCMMGCZC"
      },
      "outputs": [],
      "source": [
        "\n",
        "def build_model():\n",
        "    model = keras.Sequential([\n",
        "        Dense(20, activation=tf.nn.relu, input_shape=[len(train_features[0])]),\n",
        "        Dense(1)\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=tf.optimizers.Adam(),\n",
        "                  loss='mae',\n",
        "                  metrics='mean_absolute_error')\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkM_Ixa_GCZD"
      },
      "source": [
        "### Step 4: Training the Model\n",
        "Training the neural network model requires the following steps:\n",
        "\n",
        "\n",
        "- Define a custom callback class **PrintDot**, which prints a dot for every epoch during training.\n",
        "\n",
        "- Create an instance of the model using the **build_model** function.\n",
        "\n",
        "- Create an instance of EarlyStopping callback, which monitors the validation loss and stops training if it doesn't improve after a certain number of epochs (specified by patience).\n",
        "\n",
        "- Train the model using the training features and labels. It runs for 200 epochs, with a validation split of 0.1 (10% of the training data used for validation). The callbacks parameter includes **early_stop** and **PrintDot** callbacks.\n",
        "\n",
        "- Create a Pandas **DataFrame hist** from the history object returned by the model.fit method. It contains the recorded training and validation metrics.\n",
        "\n",
        "- Extract the last value of the validation mean absolute error (MAE) from the hist DataFrame and assign it to the variable mae_final.\n",
        "\n",
        "- Print the final MAE on the validation set, rounded to three decimal places."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WocKoO9GCZE",
        "outputId": "dc1cfcf8-0b51-4070-f751-6e0fc1a99e8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "....................................................................................................\n",
            "....................................................................................................\n",
            "Final  Mean absolute  Error on validation set: 2.596\n"
          ]
        }
      ],
      "source": [
        "class PrintDot(keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs):\n",
        "        if epoch % 100 == 0: print('')\n",
        "        print('.', end='')\n",
        "\n",
        "model = build_model()\n",
        "\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=50)\n",
        "history = model.fit(train_features, train_labels, epochs=200, verbose=0, validation_split = 0.1,\n",
        "                    callbacks=[early_stop, PrintDot()])\n",
        "\n",
        "hist = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "\n",
        "mae_final = float(hist['val_mean_absolute_error'].tail(1))\n",
        "\n",
        "print()\n",
        "print('Final  Mean absolute  Error on validation set: {}'.format(round(mae_final, 3)))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation**\n",
        "\n",
        "As shown, the final mean absolute error on the validation set is 2.596."
      ],
      "metadata": {
        "id": "7r7uOD6jLYx-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- It normalizes the test features based on the mean and standard deviation of the training set.\n",
        "- It evaluates the model's performance on the normalized test features and prints the mean absolute error (MAE) on the test set."
      ],
      "metadata": {
        "id": "MZeUxYF9HML2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQbYz8kMGCZE",
        "outputId": "2df65185-6d77-4fe1-df4f-86ad4acf1166"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 2ms/step - loss: 3.1237 - mean_absolute_error: 3.1237\n",
            " Mean absolute  Error on test set: 3.124\n"
          ]
        }
      ],
      "source": [
        "test_features_norm = (test_features - train_mean) / train_std\n",
        "mae,  _ = model.evaluate(test_features_norm, test_labels)\n",
        "#rmae = np.sqrt(mae)\n",
        "print(' Mean absolute  Error on test set: {}'.format(round(mae, 3)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation**\n",
        "\n",
        "The output indicates the following:\n",
        "\n",
        "- The evaluation was performed on 4 data points.\n",
        "- The loss value (mean squared error) on the test set is 3.1237.\n",
        "- The mean absolute error on the test set is also 3.1237.\n",
        "- The mean absolute error, when rounded, is 3.124.\n",
        "\n",
        "In summary, the model achieved a loss value of 3.1237 and a mean absolute error of 3.1237, which translates to a mean absolute error of approximately 3.124."
      ],
      "metadata": {
        "id": "vCrX2XQzL1x3"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}